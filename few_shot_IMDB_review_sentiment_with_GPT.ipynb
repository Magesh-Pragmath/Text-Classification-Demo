{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f432a1",
   "metadata": {},
   "source": [
    "# üìò Notebook Summary: Sentiment Classification of IMDB Reviews using GPT-3.5-Turbo (Few-Shot Prompting)\n",
    "\n",
    "This notebook performs **sentiment classification** of IMDB movie reviews using **few-shot prompting** with the `gpt-3.5-turbo` model via the **Azure OpenAI API**. The dataset is sourced from **Hugging Face's `imdb` corpus**.\n",
    "\n",
    "### üîç Key Components:\n",
    "- **Dataset**: IMDB reviews with binary sentiment labels (`positive`, `negative`).\n",
    "- **Few-shot Prompting**: The notebook constructs prompts with example reviews and their sentiments to guide the model.\n",
    "- **OpenAI API Integration**: Uses `openai.ChatCompletion.create` to classify test reviews.\n",
    "- **Evaluation**: Computes the **micro F1 score** to evaluate GPT's performance on unseen reviews.\n",
    "\n",
    "### ‚öôÔ∏è Techniques Used:\n",
    "- Environment configuration via `.env` and `dotenv`.\n",
    "- Prompt engineering for `gpt-3.5-turbo` in chat format.\n",
    "- Use of `scikit-learn` for data splitting and F1 scoring.\n",
    "- Batched inference using OpenAI API with progress monitoring via `tqdm`.\n",
    "\n",
    "This notebook is ideal for evaluating **LLM few-shot classification capabilities** on real-world, sentiment-labeled text data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aacb72ab",
   "metadata": {},
   "source": [
    "## Import Libraries and API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "892a3945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all Python packages required to access the Azure Open AI API.\n",
    "# Import additional packages required to access datasets and create examples.\n",
    "\n",
    "import json\n",
    "import random\n",
    "import tiktoken\n",
    "import session_info\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import openai\n",
    "\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828b1121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = openai.OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0fc8529",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHATGPT_MODEL = \"gpt-3.5-turbo\"\n",
    "deployment_name = CHATGPT_MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3bad48",
   "metadata": {},
   "source": [
    "## Load and Process Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a00d335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_corpus = load_dataset(\"imdb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f37081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f607811",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_train_df = imdb_reviews_corpus['train'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7369a45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    25000 non-null  object\n",
      " 1   label   25000 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 390.8+ KB\n"
     ]
    }
   ],
   "source": [
    "imdb_reviews_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cbc19aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "0    12500\n",
       "1    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_train_df.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8209a932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I rented I AM CURIOUS-YELLOW from my video sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I Am Curious: Yellow\" is a risible and preten...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If only to avoid making this type of film in t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This film was probably inspired by Godard's Ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oh, brother...after hearing about this ridicul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  I rented I AM CURIOUS-YELLOW from my video sto...      0\n",
       "1  \"I Am Curious: Yellow\" is a risible and preten...      0\n",
       "2  If only to avoid making this type of film in t...      0\n",
       "3  This film was probably inspired by Godard's Ma...      0\n",
       "4  Oh, brother...after hearing about this ridicul...      0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "496149f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_train_df['sentiment'] = np.where(imdb_reviews_train_df.label == 1, \"positive\", \"negative\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed0d85af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6671</th>\n",
       "      <td>Herbie, the Volkswagen that thinks like a man,...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23913</th>\n",
       "      <td>\"Kolchak: the Night Stalker\" is a hugely enter...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21140</th>\n",
       "      <td>I have to start off by apologizing because I t...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19652</th>\n",
       "      <td>Although Cinderella isn't the obvious choice f...</td>\n",
       "      <td>1</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4281</th>\n",
       "      <td>Rather than move linearly from beginning to en...</td>\n",
       "      <td>0</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  label sentiment\n",
       "6671   Herbie, the Volkswagen that thinks like a man,...      0  negative\n",
       "23913  \"Kolchak: the Night Stalker\" is a hugely enter...      1  positive\n",
       "21140  I have to start off by apologizing because I t...      1  positive\n",
       "19652  Although Cinderella isn't the obvious choice f...      1  positive\n",
       "4281   Rather than move linearly from beginning to en...      0  negative"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_train_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36a6c091",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "negative    12500\n",
       "positive    12500\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imdb_reviews_train_df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6851778",
   "metadata": {},
   "source": [
    "## Split Dataset to Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f7c0922",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_reviews_examples_df, imdb_reviews_gold_examples_df = train_test_split(\n",
    "    imdb_reviews_train_df, #<- the full dataset\n",
    "    test_size=0.2, #<- 20% random sample selected for gold examples\n",
    "    random_state=42 #<- ensures that the splits are the same for every session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2656f842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000, 3), (5000, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(imdb_reviews_examples_df.shape, imdb_reviews_gold_examples_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c5fb4e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_select = ['text', 'sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d25a020d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gold_examples = (\n",
    "        imdb_reviews_gold_examples_df.loc[:, columns_to_select]\n",
    "                                     .sample(50, random_state=42) #<- ensures that gold examples are the same for every session\n",
    "                                     .to_json(orient='records')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "77a93ca8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Like I said at the top, four stars just aren\\'t enough. It\\'s one of the best films I\\'ve ever seen in my almost 17 years of life. For the people that don\\'t really like it or understand it, you must not have a real appreciation for art or you might have a short attention span.<br /><br />Even if I haven\\'t seen all his films yet, I\\'d have to say that this is Spielberg at his peak. It\\'s pretty sad to see that movies as great as \"The Color Purple\" don\\'t come along too often \\'cause I think all of us are in desperate need of first-class motion picture entertainment in these hard times.<br /><br />Movies like this are more than just movies; they\\'re pieces of art that need to be appreciated more.<br /><br />The idea that it was nominated for 11 Oscars (even Best Picture of the Year) and didn\\'t get one trophy is a sign of how blind and stupid Hollywood can be sometimes. Spielberg wasn\\'t even nominated for Best Director! It should have swept the Oscars that year.<br /><br />The film clearly shows you how unfair life is for some people.<br /><br />If only movies were still this good....',\n",
       " 'sentiment': 'positive'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(gold_examples)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979aa20e",
   "metadata": {},
   "source": [
    "## Initialize System Message and User Message Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99f485cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_message_template = \"\"\"```{movie_review}```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "76cfd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_system_message = \"\"\"\n",
    "Classify the sentiment of movie reviews presented in the input as 'positive' or 'negative'.\n",
    "Movie reviews will be delimited by triple backticks in the input.\n",
    "Answer only 'positive' or 'negative'. Do not explain your answer.\n",
    "\n",
    "Instructions:\n",
    "1. Carefully read the text of the review and think through the options for sentiment provided\n",
    "2. Consider the overall sentiment of the review and estimate the probability of the review being positive\n",
    "\n",
    "To reiterate, your answer should strictly only contain the label: positive or negative.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c895dcf8",
   "metadata": {},
   "source": [
    "## Extract Postive and negative examples from Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e6d1c48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_reviews = (imdb_reviews_examples_df.sentiment == 'positive')\n",
    "negative_reviews = (imdb_reviews_examples_df.sentiment == 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7292f9cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((20000,), (20000,))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(positive_reviews.shape, negative_reviews.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "89169a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_examples(dataset, n=4):\n",
    "\n",
    "    \"\"\"\n",
    "    Return a JSON list of randomized examples of size 2n with two classes.\n",
    "    Create subsets of each class, choose random samples from the subsets,\n",
    "    merge and randomize the order of samples in the merged list.\n",
    "    Each run of this function creates a different random sample of examples\n",
    "    chosen from the training data.\n",
    "\n",
    "    Args:\n",
    "        dataset (DataFrame): A DataFrame with examples (text + label)\n",
    "        n (int): number of examples of each class to be selected\n",
    "\n",
    "    Output:\n",
    "        randomized_examples (JSON): A JSON with examples in random order\n",
    "    \"\"\"\n",
    "\n",
    "    positive_reviews = (dataset.sentiment == 'positive')\n",
    "    negative_reviews = (dataset.sentiment == 'negative')\n",
    "    columns_to_select = ['text', 'sentiment']\n",
    "\n",
    "    positive_examples = dataset.loc[positive_reviews, columns_to_select].sample(n)\n",
    "    negative_examples = dataset.loc[negative_reviews, columns_to_select].sample(n)\n",
    "\n",
    "    examples = pd.concat([positive_examples, negative_examples])\n",
    "    # sampling without replacement is equivalent to random shuffling\n",
    "    randomized_examples = examples.sample(2*n, replace=False)\n",
    "\n",
    "    return randomized_examples.to_json(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e6f1c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = create_examples(imdb_reviews_examples_df, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59ee5dc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'text': \"I'm shocked that there were people who liked this movie..I saw it at Tribeca and most of the audience laughed through it at scenes that were not meant to be funny. I felt bad because the lead actress was in the audience, but honestly the plot to this movie needed MAJOR revision..it didn't even make sense, one second the characters question what exactly it is that they're snorting..the next scene they're hopelessly addicted and figure out how to make it?? Also the ending just took the cake..I'm not going to spoil the magnificent conclusion..but it pretty much blended right in with the rest of the horrible plot/script...see this movie for comedy if you must..\",\n",
       "  'sentiment': 'negative'},\n",
       " {'text': 'This is easily a 9. Michel Serrault, known more for comic roles in the earlier part of his acting career, does a stunning, even worryingly stunning job of impersonating Dr Petiot, a legendary French serial killer.<br /><br />He is just so believable at every and any moment in the film, that the actor completely disappears behind the character - only the very best ever achieve this feat, and when they do it is only in a handful of parts at best.<br /><br />The whole story (a real story which happened in 20th century France) is so powerful, so sinister - it makes for a very strong film that one remembers for a long, long time.',\n",
       "  'sentiment': 'positive'},\n",
       " {'text': 'i completely agree with jamrom4.. this was the single most horrible movie i have ever seen.. holy crap it was terrible.. i was warned not to see it..and foolishly i watched it anyway.. about 10 minutes into the painful experience i completely gave up on watching the atrocity..but sat through until the end..just to see if i could.. well i did and now i wish i had not..it was disgusting..nothing happened and the ending was all preachy..no movie that bad has the right to survive..i implore all of you to spare yourself the terror of fatty drives the bus..if only i had heeded the same warning..please save yourself from this movie..i have a feeling those who rated it highly were involved in the making of the movie..and should all be wiped off the face of the planet..',\n",
       "  'sentiment': 'negative'},\n",
       " {'text': 'I had watched (and recorded) this a few years back on local TV and, having been underwhelmed by it, I subsequently erased the tape; however, when it was released by MGM as part of a \"Midnite Movie\" double-feature DVD of Curtis Harrington/Shelley Winters films for a very affordable price, I couldn\\'t resist giving it a second look (this has since gone out-of-print). Actually, I received the DVD a few months ago but only now, with Harrington\\'s passing, did I get to it; thankfully, this time around I was more receptive to the film and, in fact, now consider it one of the more satisfying WHATEVER HAPPENED TO BABY JANE? (1962) imitations (with whom, incidentally, it shared screenwriter Henry Farrell).<br /><br />The film offers a splendid evocation of 1930s Depression America - with its child-star craze and sensational murders (exploited during the fake newsreel opening); it\\'s stylishly made (kudos to Lucien Ballard\\'s cinematography and the set design by Eugene Lourie\\') and boasts an effective David Raksin score. Shelley Winters, Debbie Reynolds and Michael MacLiammoir deliver excellent performances; the latter is especially impressive as the larger-than-life and vaguely sinister diction coach (though he ultimately proves a mere red herring!). Also featured are Dennis Weaver and Agnes Moorehead (hers is only a cameo, really, as the evangelist she plays is mostly heard over the radio).<br /><br />Many seemed to regret the inclusion of musical numbers by the kids (including an amusing Mae West imitation), but I personally wasn\\'t bothered by them; the film does slightly overstay its welcome due to an unhurried pace and (perhaps needlessly) convoluted plot. Reynolds - a musical star herself - is ideally cast as the dancing-school owner and, despite their on-set rivalry, she and Winters work well together. The latter, in fact, gives a more balanced depiction of paranoia and insanity than in WHOEVER SLEW AUNTIE ROO? (1971); the narrative, then, comes up with a number of ironic twists that lead up to the expected Grand Guignol-type denouement. Apparently, the film was toned down (it originally contained more gore and even a suggestion of lesbianism!) by producer Martin Ransohoff - against Harrington\\'s wishes - in order to get a PG rating...',\n",
       "  'sentiment': 'positive'}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json.loads(examples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d04ff67",
   "metadata": {},
   "source": [
    "## Create Few Shot Prompt with Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7aac60b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prompt(system_message, examples, user_message_template):\n",
    "\n",
    "    \"\"\"\n",
    "    Return a prompt message in the format expected by the Open AI API.\n",
    "    Loop through the examples and parse them as user message and assistant\n",
    "    message.\n",
    "\n",
    "    Args:\n",
    "        system_message (str): system message with instructions for sentiment analysis\n",
    "        examples (str): JSON string with list of examples\n",
    "        user_message_template (str): string with a placeholder for movie reviews\n",
    "\n",
    "    Output:\n",
    "        final_prompt (List): A list of dictionaries in the Open AI prompt format\n",
    "    \"\"\"\n",
    "\n",
    "    final_prompt = [{'role':'system', 'content': system_message}]\n",
    "\n",
    "    for example in json.loads(examples):\n",
    "        example_review = example['text']\n",
    "        example_sentiment = example['sentiment']\n",
    "\n",
    "        final_prompt.append(\n",
    "            {\n",
    "                'role': 'user',\n",
    "                'content': user_message_template.format(\n",
    "                    movie_review=example_review\n",
    "                )\n",
    "            }\n",
    "        )\n",
    "\n",
    "        final_prompt.append(\n",
    "            {'role': 'assistant', 'content': f\"{example_sentiment}\"}\n",
    "        )\n",
    "\n",
    "    return final_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d5e8382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cot_few_shot_prompt = create_prompt(\n",
    "    cot_system_message,\n",
    "    examples,\n",
    "    user_message_template\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f342e4e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \"\\nClassify the sentiment of movie reviews presented in the input as 'positive' or 'negative'.\\nMovie reviews will be delimited by triple backticks in the input.\\nAnswer only 'positive' or 'negative'. Do not explain your answer.\\n\\nInstructions:\\n1. Carefully read the text of the review and think through the options for sentiment provided\\n2. Consider the overall sentiment of the review and estimate the probability of the review being positive\\n\\nTo reiterate, your answer should strictly only contain the label: positive or negative.\\n\"},\n",
       " {'role': 'user',\n",
       "  'content': \"```I didn't expect much from this film, but oh brother, what a stinker.<br /><br />I found this gem in a giant crate of awful $5 DVD's at Walmart (where else)? As cheap as this disc was, I feel ripped off. The special effects had a high school look to them, the camera work marred by wobbly tripods and sketchy lighting and the acting was a perfect example of the 'Christian School'. One can imagine the long and exhausting 'prayer meetings' by the production company after seeing the rushes come back - the people who bankrolled this thing must have had seriously anti-biblical feelings towards the inept production company that cranked this thing out. Think of their anguish as they saw their $914.86 investment go up in smoke.<br /><br />Someone asked why Christian movies are so bad - perhaps the Xian film-makers need to look at GOOD movies and attempt to copy some of the things that make them so good. Believable stories and characters, less hysterical arm-waving and fanaticism, oh, and a story that appeals to -everyone-, not just true believers. I.e. Stop The Sermon, Save It For Church. Take the Omen or Prophesy series, for example. Excellent films with compelling story lines, great cinematography and intense music. No hysterical arm-waving. No preaching.<br /><br />If this film had a laugh track it would have been MUCH better.```\"},\n",
       " {'role': 'assistant', 'content': 'negative'},\n",
       " {'role': 'user',\n",
       "  'content': \"```WE FAW DOWN <br /><br />Aspect ratio: 1.33:1<br /><br />Sound format: Silent<br /><br />(Black and white - Short film)<br /><br />Stan 'n' Ollie get mixed up with a couple of floozies (Kay Deslys and Vera White) after setting out to visit a theatre which burns down in their absence! Needless to say, their tyrannical wives (Vivien Oakland and Bess Flowers) are not amused...<br /><br />Leo McCarey's OK comedy laid the narrative framework for William Seiter's masterpiece SONS OF THE DESERT (1934), with L&H playing brow-beaten victims of circumstance, forced to tell a monstrous lie which backfires in spectacular fashion. Much of it is very funny, especially the scene in which Stan is teased by Deslys, leading to a violent game of push and shove. However, some of the fun is undercut by Oakland and Flowers, playing their roles completely straight, which adds an element of unpleasantness to the 'henpecked husband' scenario. Originally released in the UK as WE SLIP UP.```\"},\n",
       " {'role': 'assistant', 'content': 'negative'},\n",
       " {'role': 'user',\n",
       "  'content': \"```I don't know what it is I find so endearing about this film, but the first time I saw it, I wanted to see how it ended. I'm not a big fan of Paul Winfield nor of war-dramas, but I was truly wondering just how and when Winfield would find his child. All he knows is that the boy has green eyes. Truth be told, I have not seen this movie in years nor has it been shown on TV in a while, but this movie is somewhat of one man's odyssey after the pains of war. Winfield shows a very sympathetic and heart warming portrayal of a man lost by his memories. There is an underlying message in this movie that he is looking for the last shred of human morality in the aftermath of this war and the reality that he does confront. Why this movie is not yet on DVD or video is a mystery to me.```\"},\n",
       " {'role': 'assistant', 'content': 'positive'},\n",
       " {'role': 'user',\n",
       "  'content': \"```I love this movie, Jouvet, Arletty, Blier, Carn√©... almost everything has already been said about the movie, but there is one detail I'd like to shed some light onto: no footage of the real, still standing, H√¥tel du Nord (is it still? I heard it was to be demolished...) has been used for the movie - the whole scene has been rebuilt on set, the main reason being that they could not stop the traffic on the St Martin canal for several weeks.```\"},\n",
       " {'role': 'assistant', 'content': 'positive'}]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cot_few_shot_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a0014e",
   "metadata": {},
   "source": [
    "## Token Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab215fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_tokens_by_message(messages, model=CHATGPT_MODEL):\n",
    "    encoding = tiktoken.encoding_for_model(model)\n",
    "    \n",
    "    tokens_per_message = 3  # every message has <|start|> role <|content|> <|end|>\n",
    "    tokens_per_name = 1     # if 'name' is used instead of 'role'\n",
    "\n",
    "    total_tokens = 0\n",
    "    for idx, message in enumerate(messages):\n",
    "        message_tokens = tokens_per_message  # start+role+end overhead\n",
    "        for key, value in message.items():\n",
    "            message_tokens += len(encoding.encode(value))\n",
    "        print(f\"Message {idx+1} [{message['role']}]: {message_tokens} tokens\")\n",
    "        total_tokens += message_tokens\n",
    "\n",
    "    total_tokens += 3  # priming for reply (<|start|>assistant)\n",
    "    print(f\"Reply priming: 3 tokens\")\n",
    "    print(f\"\\nTotal prompt tokens: {total_tokens}\")\n",
    "    return total_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e5e7d32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Messages=cot_few_shot_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5699a9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message 1 [system]: 109 tokens\n",
      "Message 2 [user]: 147 tokens\n",
      "Message 3 [assistant]: 5 tokens\n",
      "Message 4 [user]: 149 tokens\n",
      "Message 5 [assistant]: 5 tokens\n",
      "Message 6 [user]: 180 tokens\n",
      "Message 7 [assistant]: 5 tokens\n",
      "Message 8 [user]: 520 tokens\n",
      "Message 9 [assistant]: 5 tokens\n",
      "Reply priming: 3 tokens\n",
      "\n",
      "Total prompt tokens: 1128\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1128"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_tokens_by_message(Messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c516785",
   "metadata": {},
   "source": [
    "## Predict and Evaluate Model by Micro F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "227a8476",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_and_compute_performance(prompt, gold_examples, user_message_template):\n",
    "\n",
    "    \"\"\"\n",
    "    Return the micro-F1 score for predictions on gold examples.\n",
    "    For each example, we make a prediction using the prompt. Gold labels and\n",
    "    model predictions are aggregated into lists and compared to compute the\n",
    "    F1 score.\n",
    "\n",
    "    Args:\n",
    "        prompt (List): list of messages in the Open AI prompt format\n",
    "        gold_examples (str): JSON string with list of gold examples\n",
    "        user_message_template (str): string with a placeholder for movie reviews\n",
    "\n",
    "    Output:\n",
    "        micro_f1_score (float): Micro-F1 score computed by comparing model predictions\n",
    "                                with ground truth\n",
    "    \"\"\"\n",
    "\n",
    "    model_predictions, ground_truths = [], []\n",
    "\n",
    "    for example in json.loads(gold_examples):\n",
    "        gold_input = example['text']\n",
    "        user_input = [\n",
    "            {\n",
    "                'role':'user',\n",
    "                'content': user_message_template.format(movie_review=gold_input)\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        try:\n",
    "            response = client.chat.completions.create(\n",
    "                model=deployment_name,\n",
    "                messages=prompt+user_input,\n",
    "                temperature=0, # <- Note the low temperature\n",
    "                max_tokens=2 # <- Note how we restrict the output to not more than 2 tokens\n",
    "            )\n",
    "\n",
    "            prediction = response.choices[0].message.content\n",
    "\n",
    "            model_predictions.append(prediction.strip().lower()) # <- removes extraneous white space and lowercases output\n",
    "            ground_truths.append(example['sentiment'])\n",
    "\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "    micro_f1_score = f1_score(ground_truths, model_predictions, average=\"micro\")\n",
    "\n",
    "    return micro_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8dc0284b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_and_compute_performance(cot_few_shot_prompt, gold_examples, user_message_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a29bb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
